{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a sentiment analysis model to classify movie reviews as positive or negative, based on the text of the review. This is an example of binary—or two-class—classification, an important and widely applicable kind of machine learning problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.3.0\n",
      "python: 3.6.10 |Anaconda, Inc.| (default, May  7 2020, 23:06:31) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "project_path: /Users/yuexiao/Documents/GitHub/machine_learning/Tensorflow/tutorials/ML_basics_with_Keras\n",
      "data_path: /Users/yuexiao/Documents/GitHub/machine_learning/Tensorflow/tutorials/data\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "print('tensorflow: ' + tf.__version__)\n",
    "print('python: ' + sys.version)\n",
    "print('project_path: ' + os.getcwd())\n",
    "\n",
    "# os.path.abspath(path)      ---   Return the directory name of pathname path.\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), \"../data\"))\n",
    "print('data_path: ' + data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and explore the IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [**Large Movie Review Dataset**]() that contains the text of 50,000 movie reviews from the [**Internet Movie Database**](). These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84131840/84125825 [==============================] - 280s 3us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "# tf.keras.utils.get_file()  ---   Downloads a file from a URL if it not already in the cache.\n",
    "# os.path.join(path, *paths) ---   Join one or more path components intelligently. \n",
    "dataset = tf.keras.utils.get_file(os.path.join(data_path, \"aclImdb_v1.tar.gz\"), url,\n",
    "                                    untar=True, cache_dir='.',\n",
    "                                    cache_subdir='')\n",
    "\n",
    "# os.path.dirname(path)      ---   Return a normalized absolutized version of the pathname path.\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdbEr.txt', 'test', 'imdb.vocab', 'README', 'train']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.listdir(dataset_dir)    ---   Returns a list containing the names of the entries in the directory given by path. The list is in arbitrary order.\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urls_unsup.txt',\n",
       " 'neg',\n",
       " 'urls_pos.txt',\n",
       " 'unsup',\n",
       " 'urls_neg.txt',\n",
       " 'pos',\n",
       " 'unsupBow.feat',\n",
       " 'labeledBow.feat']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `aclImdb/train/pos` and `aclImdb/train/neg` directories contain many text files, each of which is a single movie review. Let's take a look at one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.\n"
     ]
    }
   ],
   "source": [
    "sample_file = os.path.join(train_dir, 'pos/1181_9.txt')\n",
    "with open(sample_file) as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data off disk and prepare it into a format suitable for training. To do so, you will use the helpful *text_dataset_from_directory utility*, which expects a directory structure as follows.\n",
    "\n",
    "```\n",
    "main_directory/\n",
    "...class_a/\n",
    "......a_text_1.txt\n",
    "......a_text_2.txt\n",
    "...class_b/\n",
    "......b_text_1.txt\n",
    "......b_text_2.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare a dataset for binary classification, you will need two folders on disk, corresponding to **class_a** and **class_b**. These will be the **positive** and **negative** movie reviews, which can be found in `aclImdb/train/pos` and `aclImdb/train/neg`. As the IMDB dataset contains additional folders, you will remove them before using this utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/yuexiao/Documents/GitHub/machine_learning/Tensorflow/tutorials/data/aclImdb/train/unsup'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cb1cfd70cf6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mremove_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unsup'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# shutil.rmtree(path, ignore_errors=False, onerror=None) --- Delete an entire directory tree; path must point to a directory (but not a symbolic link to a directory)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/yuexiao/Documents/GitHub/machine_learning/Tensorflow/tutorials/data/aclImdb/train/unsup'"
     ]
    }
   ],
   "source": [
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "# shutil.rmtree(path, ignore_errors=False, onerror=None) --- Delete an entire directory tree; path must point to a directory (but not a symbolic link to a directory)\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will use the [**text_dataset_from_directory**]() utility to create a labeled [**tf.data.Dataset**](). [**tf.data**]() is a powerful collection of tools for working with data.\n",
    "\n",
    "When running a machine learning experiment, it is a best practice to divide your dataset into three splits: **train**, **validation**, and **test**.\n",
    "\n",
    "The IMDB dataset has already been divided into train and test, but it lacks a validation set. Let's create a validation set using an 80:20 split of the training data by using the *validation_split* argument below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "# tf.keras.preprocessing.text_dataset_from_directory()   ---   Generates a tf.data.Dataset from text files in a directory.\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    os.path.join(data_path, 'aclImdb/train'), \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.2, \n",
    "    subset='training', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, there are 25,000 examples in the training folder, of which you will use 80% (or 20,000) for training. As you will see in a moment, you can train a model by passing a dataset directly to ***model.fit***. If you're new to ***tf.data***, you can also iterate over the dataset and print out a few examples as follows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review b\"Having seen most of Ringo Lam's films, I can say that this is his best film to date, and the most unusual. It's a ancient china period piece cranked full of kick-ass martial arts, where the location of an underground lair full of traps and dungeons plays as big a part as any of the characters. The action is fantastic, the story is tense and entertaining, and the set design is truely memorable. Sadly, Burning Paradise has not been made available on DVD and vhs is next-to-impossible to get your mitts on, even if you near the second biggest china-town in North America (like I do). If you can find it, don't pass it up.\"\n",
      "Label 1\n",
      "Review b'Caution: May contain spoilers...<br /><br />I\\'ve seen this movie 3 times & I\\'ve liked it every time. Upon seeing it again, I\\'m always reminded of how good it is. An HBO TV movie- very well done like most of their movies are- this would\\'ve gotten Oscars for it\\'s performances had it been released for general distribution instead of made for TV.<br /><br />As I\\'m sure anyone knows from reading other reviews here, this is the story of serial murderer, Andrei Chikatilo. He murdered 56 people over 8 years in the former Soviet Union. (3 victims were buried & couldn\\'t be found so he was only convicted of 52 out of 53 of his murders.) The story actually focuses more on the forensic analyst, Victor Burakov played to perfection by Stephen Rea. A man that becomes tortured and obsessed with finding this killer despite the additional obstacles placed by party hacks, his part is essential to be sure. There is a very touching scene towards the end of the movie that mentions how in America, investigators are routinely taken off serial killer cases after 18 months whether they want to or not due to the mental strain & frustration. According to this acct, Burakov worked for over 5 years before getting his first break from it. He followed the case to its conclusion, 3 years later. In this scene, his superior, General Fetisov, played by Donald Sutherland, actually tells him he admires his dedication and apologizes for not knowing he should\\'ve given him a break sooner.<br /><br />Rea\\'s performance is so well done, he doesn\\'t overact, chew up the scenery or do anything that distracts from his portrayal of a man who is hell bent on finding his killer. He is a man with passion, but doesn\\'t show it in the same manner as is so usually portrayed in detective movies. He only occasionally gives outbursts after quietly putting up with more than most could stand under such circumstances. Rea does so much with his face, his eyes, he doesn\\'t need to overact. He just *is* - His character, so frustrated after so long, at one point, driven to frustration, he actually says he\\'d rather find 3 at one time than none in a year. Of course what he means is not that he wants more people to die, he just wants some clues to catch this man. Rea makes us feel for this man. He makes us understand but a glimpse of what it is to live with such horror and futility.<br /><br />A mutant to be sure, Chikatilo\\'s childhood was one which produces such \"monsters.\" The character of Chikatilo is very well done by Jeffrey DeMunn. He somehow (impossible though it may seem) elicits some modicum of sympathy for himself. Perhaps he is the worst of us gone terribly wrong? Either way, his performance is very well done.<br /><br />Donald Sutherland as Colonel Fetisov (later promoted to General) also does a great job. He starts out seeming to be a cynical worldly official that doesn\\'t seem much more interested in helping the investigation than anyone else blocking Burakov. But he eventually becomes more than just an assistant, he actually actively participates in helping Burakov. There is also a very nice turn by Max Von Sydow as the psychiatrist brought in to help profile and figure out what kind of deviant they are looking for.<br /><br />Although this movie deals with a morbid, grotesque and violent story, it really is more about what it takes to catch a killer than the killer himself. All around a very well done movie with fine performances and a great screenplay. The screenplay manages to do what the best of this type of movie does: give factual events & place them meaningfully inside a dramatic framework that makes you feel like you know the people *behind* the facts.<br /><br />9 out of 10 stars'\n",
      "Label 1\n",
      "Review b\"from the view of a NASCAR Maniac like I am, the movie is interesting. You can see many race cars from 1983. Even tough, the racing scenes are not that much realistic. But I have to admit, that I haven't seen any race before 1995, because before that time, they didn't show any NASCAR races in Germany)<br /><br />from the view of a Burt Reynolds fan like I am, the movie basically is what we are used to see from Reynolds in the 80's: Burt behind the wheel of a fast car, like in his Bandit Movies.<br /><br />If you love NASCAR and Burt Reynolds, this movie is a must-see. If you only love one of this 2 things, I also recommend to watch it. If you like neither NASCAR nor Burt Reynolds, you still should give it a chance, but remember, this movie was far away from winning an Oscar Academy Award.<br /><br />It is the typical humor of the 80's. If you like movies like the Cannonball Movies, and Police Academy, you will also like that one.\"\n",
      "Label 1\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(\"Review\", text_batch.numpy()[i])\n",
    "    print(\"Label\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the reviews contain raw text (with punctuation and occasional HTML tags like `<br/>`). You will show how to handle these in the following section.\n",
    "\n",
    "The labels are 0 or 1. To see which of these correspond to positive and negative movie reviews, you can check the **class_names** property on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to neg\n",
      "Label 1 corresponds to pos\n"
     ]
    }
   ],
   "source": [
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    os.path.join(data_path, 'aclImdb/train'),\n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.2, \n",
    "    subset='validation', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    os.path.join(data_path, 'aclImdb/test'),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will standardize, tokenize, and vectorize the data using the helpful [**preprocessing.TextVectorization**]() layer.\n",
    "\n",
    "Standardization refers to preprocessing the text, typically to remove punctuation or HTML elements to simplify the dataset. Tokenization refers to splitting strings into tokens (for example, splitting a sentence into individual words, by splitting on whitespace). Vectorization refers to converting tokens into numbers so they can be fed into a neural network. All of these tasks can be accomplished with this layer.\n",
    "\n",
    "As you saw above, the reviews contain various HTML tags like `<br />`. These tags will not be removed by the default standardizer in the TextVectorization layer (which converts text to lowecase and strips punctuation by default, but doesn't strip HTML). You will write a custom standardization function to remove the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will create a ***TextVectorization*** layer. you will use this layer to standardize, tokenize, and vectorize our data. You set the ***output_mode*** to ***int*** to create unique integer indices for each token.\n",
    "\n",
    "Note that you're using the default split function, and the custom standardization function you defined above. You'll also define some constants for the model, like an explicit maximum ***sequence_length***, which will cause the layer to pad or truncate sequences to exactly ***sequence_length*** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "# TextVectorization\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will call [**adapt**]() to fit the state of the preprocessing layer to the dataset. This will cause the model to build an index of strings to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f8b942adea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7f8b942adea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "\n",
    "# normal map() and lambda\n",
    "# map()   ---   function returns a map object(which is an iterator) of the results after applying the given function to each item of a given iterable (list, tuple etc.)\n",
    "# lambda The lambda operator or lambda function is a way to create small anonymous functions. \n",
    "#        i.e. functions without a name. These functions are throw-away functions, \n",
    "#        i.e. they are just needed where they have been created\n",
    "# Lambda functions are mainly used in combination with the functions filter(), map() and reduce().\n",
    "\n",
    "\n",
    "# tf.data.map()   ---   Maps map_func across the elements of this dataset.\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "# TextVectorization.adapt()   ---   Fits the state of the preprocessing layer to the dataset.\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to see the result of using this layer to preprocess some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    # tf.expand_dims\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review tf.Tensor(b'\"Emma\" was a product of what might be called by the First Great Jane Austen Cycle of the mid-nineties, and it was recently shown on British television, doubtless because of the interest in the author created by the Second Great Jane Austen Cycle which started with \"Pride and Prejudice\" two years ago. We currently have in the cinemas the Austen biopic \"Becoming Jane\", and ITV have recently produced three TV movies based on Austen novels. These include \"Northanger Abbey\", the only one of the six major novels not to have been filmed previously, so the cycle should now be complete. No doubt, however, there will be more to come in the near future. (There is, after all, her juvenile \"Love and Freindship\" (sic), the short novella \"Lady Susan\", and someone, somewhere, has doubtless supplied endings to her two unfinished fragments \"The Watsons\" and \"Sanditon\". Then there are all those Austen sequels churned out by modern writers\\xc2\\x85\\xc2\\x85\\xc2\\x85).<br /><br />The main character is Emma Woodhouse, a young lady from an aristocratic family in Regency England. (Not, as some reviewers have assumed, Victorian England- Austen died before Queen Victoria was even born). Emma is, financially, considerably better off than most Austen heroines such as Elizabeth Bennett or Fanny Price, and has no need to find herself a wealthy husband. Instead, her main preoccupation seems to be finding husbands for her friends. She persuades her friend Harriet to turn down a proposal of marriage from a young farmer, Robert Martin, believing that Harriet should be setting her sights on the ambitious clergyman Mr Elton. This scheme goes disastrously wrong, however, as Elton has no interest in Harriet, but has fallen in love with Emma herself. The speed with which Emma rejects his proposal makes one wonder just why she was so keen to match her friend with a man she regards (with good reason) as an unsuitable marriage partner for herself. This being a Jane Austen plot, Emma turns out to be less of a committed spinster than she seems, and she too finds herself falling in love, leading to further complications.<br /><br />Emma always insists that she will not marry without affection, and when she does find a partner, the handsome Mr Knightley, we feel that this will indeed be an affectionate marriage. It does not, however, seem likely to be a very passionate one (unlike, say, that of Elizabeth Bennett and Mr Darcy). Knightley, who is sixteen years older than Emma (she is 21, he 37), and related to her by marriage, is more like a father-figure than a lover. Much more of a father-figure, in fact, than her actual father, a querulous and selfish old hypochondriac who seems more like her grandfather. When Emma is rude to her unbearably garrulous and tedious friend Miss Bates, it is Knightley who chides her for her lack of manners. (His surname is probably meant to indicate his gentlemanly nature- nineteenth-century gentlemen liked to think of themselves as the modern equivalent of mediaeval knights with their elaborate codes of chivalry). Both Gwyneth Paltrow and Jeremy Northam play their parts very well, but this is not really one of the great screen romances.<br /><br />Of the other characters, I liked Juliet Stephenson\\'s vulgar Mrs Elton and Toni Collette\\'s Harriet. I know that in the novel Harriet was a na\\xc3\\xafve young teenager, whereas here she is more like the character Collette played in \"Muriel\\'s Wedding\"- a gauche, slightly overweight twentysomething, fretting about her chances of finding a man. Nevertheless, I felt that this characterisation worked well in the context of the film and did not detract from Austen\\'s themes.<br /><br />\"Emma\" is one of Austen\\'s more light-hearted works, without the darker overtones of \"Mansfield Park\" or even \"Pride and Prejudice\", and this is reflected on screen. We see a world of beauty and grace, full of stately homes and elegant costumes and fine manners. Apart from the ruffianly gypsies, who make a very brief appearance, the only \"poor\" people we see are Mrs Bates and her daughter, and, as they live in the sort of picturesque rose-strewn thatched cottage which today would change hands for over \\xc2\\xa3500,000, we can be sure that their poverty is relative, not absolute. In Emma\\'s world, poverty is defined as not having your own stately home. This is, of course, not a comprehensive picture of early nineteenth-century life, but nobody has ever claimed Austen as the Regency equivalent of a kitchen-sink realist. Sophisticated romantic comedy, combined with a keen eye for analysing human character, was more in her line.<br /><br />I would not rate this film quite as highly as the 1994 \"Sense and Sensibility\" or the recent \"Pride and Prejudice\"- it tends to drag a bit in the middle, although it has a strong beginning and strong ending- but it is, in the main, a highly enjoyable Austen adaptation. 7/10', shape=(), dtype=string)\n",
      "Label pos\n",
      "Vectorized review (<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
      "array([[2528,   13,    4, 2218,    5,   48,  227,   26,  488,   32,    2,\n",
      "          83,   86, 1007, 6768, 6996,    5,    2,    1,    3,    9,   13,\n",
      "         986,  581,   20,  681,  708,    1,   84,    5,    2,  598,    8,\n",
      "           2, 2174, 1033,   32,    2,  333,   86, 1007, 6768, 6996,   60,\n",
      "         606,   16, 3114,    3, 5437,  104,  149,  589,   71, 3780,   25,\n",
      "           8,    2, 4959,    2, 6768, 6887, 1587, 1007,    3,    1,   25,\n",
      "         986, 1118,  297,  243,   91,  443,   20, 6768, 2630,  129, 1429,\n",
      "           1,    1,    2,   61,   28,    5,    2, 1539,  653, 2630,   21,\n",
      "           6,   25,   74,  814, 2353,   37,    2, 6996,  139,  148,   26,\n",
      "         555,   57,  803,  189,   47,   76,   26,   50,    6,  203,    8,\n",
      "           2,  781,  701,   47,    7,  101,   30,   39, 3697,  115,    3,\n",
      "           1,    1,    2,  350,    1,  729, 2744,    3,  282, 1116,   43,\n",
      "           1,    1, 4055,    6,   39,  104,    1,    1,    2,    1,    3,\n",
      "           1,   92,   47,   23,   30,  143, 6768, 2141,    1,   44,   32,\n",
      "         709,    1,    2,  275,  106,    7, 2528,    1,    4,  181,  729,\n",
      "          35,   33,    1,  215,    8,    1, 1777,   21,   14,   46, 1870,\n",
      "          25, 5293, 7152, 1777, 6768, 1071,  153, 1573, 2375,   13,   53,\n",
      "        1461, 2528,    7,    1, 5765,  122,  127,   70,   88, 6768, 8660,\n",
      "         135,   14, 2722, 7422,   41,    1, 1841,    3,   43,   57,  349,\n",
      "           6,  163,  733,    4, 3109,  672,  291,   39,  275,    1,  180,\n",
      "           6,   26, 1578, 2978,   15,   39,  335,   55,    1,   39,  469,\n",
      "        5926,    6,  459,  185,    4,    1,    5, 1357,   35,    4,  181,\n",
      "        6023,  639, 1558, 3206,   12, 5926,  139,   26]])>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "# next()   ---   retrieves next item from the iterator\n",
    "# iter()   ---   creates an object which can be iterated one element at a time.\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "print(\"Label\", raw_train_ds.class_names[first_label])\n",
    "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, each token has been replaced by an integer. You can lookup the token (string) that each integer corresponds to by calling [**.get_vocabulary()**]() on the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287 --->  silent\n",
      " 313 --->  night\n",
      "Vocabulary size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n",
    "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
    "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are nearly ready to train your model. As a final preprocessing step, you will apply the TextVectorization layer you created earlier to the train, validation, and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function vectorize_text at 0x7f8b93ebe048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function vectorize_text at 0x7f8b93ebe048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are two important methods you should use when loading data to make sure that I/O does not become blocking.\n",
    "\n",
    "[**.cache()**](https://www.tensorflow.org/guide/data_performance#caching) keeps data in memory after it's loaded off disk. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache, which is more efficient to read than many small files.\n",
    "\n",
    "[**.prefetch()**](https://www.tensorflow.org/guide/data_performance#prefetching) overlaps data preprocessing and model execution while training.\n",
    "\n",
    "You can learn more about both methods, as well as how to cache data to disk in the [data performance guide](https://www.tensorflow.org/guide/data_performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160016    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_features + 1, embedding_dim),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layers are stacked sequentially to build the classifier:\n",
    "\n",
    "The first layer is an Embedding layer. This layer takes the integer-encoded reviews and looks up an embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding). To learn more about embeddings, see the [**word embedding tutorial**](https://www.tensorflow.org/tutorials/text/word_embeddings).\n",
    "Next, a [**GlobalAveragePooling1D**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling1D) layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n",
    "This fixed-length output vector is piped through a fully-connected ([**Dense**]()) layer with 16 hidden units.\n",
    "The last layer is densely connected with a single output node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model needs a loss function and an optimizer for training. Since this is a binary classification problem and the model outputs a probability (a single-unit layer with a sigmoid activation), you'll use [**losses.BinaryCrossentropy**]() loss function.\n",
    "\n",
    "Now, configure the model to use an optimizer and a loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.BinaryCrossentropy(from_logits=True), optimizer='adam', metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will train the model by passing the dataset object to the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b954c9d08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b954c9d08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.6664 - binary_accuracy: 0.6924WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b94a8ed90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b94a8ed90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "625/625 [==============================] - 11s 18ms/step - loss: 0.6662 - binary_accuracy: 0.6925 - val_loss: 0.6178 - val_binary_accuracy: 0.7698\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.5514 - binary_accuracy: 0.7987 - val_loss: 0.5004 - val_binary_accuracy: 0.8202\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.4465 - binary_accuracy: 0.8443 - val_loss: 0.4216 - val_binary_accuracy: 0.8470\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3800 - binary_accuracy: 0.8645 - val_loss: 0.3748 - val_binary_accuracy: 0.8616\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3371 - binary_accuracy: 0.8781 - val_loss: 0.3459 - val_binary_accuracy: 0.8668\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3064 - binary_accuracy: 0.8883 - val_loss: 0.3266 - val_binary_accuracy: 0.8710\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2830 - binary_accuracy: 0.8959 - val_loss: 0.3133 - val_binary_accuracy: 0.8734\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2633 - binary_accuracy: 0.9039 - val_loss: 0.3036 - val_binary_accuracy: 0.8758\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2475 - binary_accuracy: 0.9100 - val_loss: 0.2968 - val_binary_accuracy: 0.8762\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2324 - binary_accuracy: 0.9151 - val_loss: 0.2919 - val_binary_accuracy: 0.8786\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 14ms/step - loss: 0.3104 - binary_accuracy: 0.8731\n",
      "Loss:  0.3104218542575836\n",
      "Accuracy:  0.8731200098991394\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fairly naive approach achieves an accuracy of about 86%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a plot of accuracy and loss over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**model.fit()**]() returns a [**History**]() object that contains a dictionary with everything that happened during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four entries: one for each monitored metric during training and validation. You can use these to plot the training and validation loss for comparison, as well as the training and validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot, the dots represent the training loss and accuracy, and the solid lines are the validation loss and accuracy.\n",
    "\n",
    "Notice the training loss decreases with each epoch and the training accuracy increases with each epoch. This is expected when using a gradient descent optimization—it should minimize the desired quantity on every iteration.\n",
    "\n",
    "This isn't the case for the validation loss and accuracy—they seem to peak before the training accuracy. This is an example of overfitting: the model performs better on the training data than it does on data it has never seen before. After this point, the model over-optimizes and learns representations specific to the training data that do not generalize to test data.\n",
    "\n",
    "For this particular case, you could prevent overfitting by simply stopping the training when the validation accuracy is no longer increasing. One way to do so is to use the [**EarlyStopping callback**]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, you applied the **TextVectorization** layer to the dataset before feeding text to the model. If you want to make your model capable of processing raw strings (for example, to simplify deploying it), you can include the **TextVectorization** layer inside your model. To do so, you can create a new model using the weights you just trained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b93af8268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b93af8268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.3104 - accuracy: 0.8731\n",
      "0.8731200098991394\n"
     ]
    }
   ],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "  vectorize_layer,\n",
    "  model,\n",
    "  layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Test it with `raw_test_ds`, which yields raw strings\n",
    "loss, accuracy = export_model.evaluate(raw_test_ds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including the text preprocessing logic inside your model enables you to export a model for production that simplifies deployment, and reduces the potential for [**train/test skew**](https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew).\n",
    "\n",
    "There is a performance difference to keep in mind when choosing where to apply your TextVectorization layer. Using it outside of your model enables you to do asynchronous CPU processing and buffering of your data when training on GPU. So, if you're training your model on the GPU, you probably want to go with this option to get the best performance while developing your model, then switch to including the TextVectorization layer inside your model when you're ready to prepare for deployment.\n",
    "\n",
    "Visit this [**tutorial**](https://www.tensorflow.org/tutorials/keras/save_and_load) to learn more about saving models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
